{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 - Train User-specific Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from swlda import SWLDA\n",
    "from scipy.stats import norm\n",
    "\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TIMESTAMPS = 195\n",
    "EPOCH_SIZE = 15\n",
    "NUM_SESSIONS = 6\n",
    "directory = '/Users/zionshane/Desktop/Duke/Research/BCI_data/EDFData-StudyA'\n",
    "obj = 1\n",
    "obj = str(obj) if obj > 10 else '0'+str(obj)\n",
    "paradigm = 'RD'\n",
    "obj_directory = directory + f'/A{obj}/SE001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features,train_response = utils.load_data(dir=obj_directory,\n",
    "                                                obj=obj,\n",
    "                                                num_timestamps=NUM_TIMESTAMPS,\n",
    "                                                epoch_size=EPOCH_SIZE,\n",
    "                                                type=paradigm,\n",
    "                                                mode='train',\n",
    "                                                num_sessions=NUM_SESSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features,test_response = utils.load_data(dir=obj_directory,\n",
    "                                              obj=obj,\n",
    "                                              num_timestamps=NUM_TIMESTAMPS,\n",
    "                                              epoch_size=EPOCH_SIZE,\n",
    "                                              type=paradigm,\n",
    "                                              mode='test',\n",
    "                                              num_sessions=NUM_SESSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SWLDA(penter=0.1, premove=0.15)\n",
    "clf.fit(train_features, train_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6314880795805274"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = clf.test(test_features, test_response)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archived code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs_list = []\n",
    "for i in range(1, 6):\n",
    "    i = str(i) if i >= 10 else '0'+str(i)\n",
    "    train_file = directory+f'/A{obj}/SE001/Train/RC/A{obj}_SE001RC_Train{i}.edf'\n",
    "    raw_train_data = mne.io.read_raw_edf(train_file, preload=True, verbose=False)\n",
    "    eeg_channels = mne.pick_channels_regexp(raw_train_data.info['ch_names'], 'EEG')\n",
    "    raw_train_data.notch_filter(freqs=60, picks=eeg_channels, verbose=False)\n",
    "    part_train_epochs = utils.get_core_epochs(raw_train_data)\n",
    "    train_epochs_list.append(part_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array([], dtype=np.float64)\n",
    "train_response = np.array([], dtype=np.float64)\n",
    "for train_epochs in train_epochs_list:\n",
    "    features, response = utils.split_data(train_epochs,\n",
    "                                          n_times=NUM_TIMESTAMPS,\n",
    "                                          n_samples=EPOCH_SIZE)\n",
    "    # I follow this stackoverflow post to concatenate np.array\n",
    "    # link: https://stackoverflow.com/a/22732845/22322930\n",
    "    train_features = np.concatenate([train_features, features]) if train_features.size else features\n",
    "    train_response = np.concatenate([train_response, response]) if train_response.size else response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epochs_list = []\n",
    "for i in range(6, 11):\n",
    "    i = str(i) if i >= 10 else '0'+str(i)\n",
    "    test_file = directory+f'/A{obj}/SE001/Test/RC/A{obj}_SE001RC_Test{i}.edf'\n",
    "    raw_test_data = mne.io.read_raw_edf(test_file, preload=True, verbose=False)\n",
    "    eeg_channels = mne.pick_channels_regexp(raw_test_data.info['ch_names'], 'EEG')\n",
    "    raw_test_data.notch_filter(freqs=60, picks=eeg_channels, verbose=False)\n",
    "    part_test_epochs = utils.get_core_epochs(raw_test_data)\n",
    "    test_epochs_list.append(part_test_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.array([], dtype=np.float64)\n",
    "test_response = np.array([], dtype=np.float64)\n",
    "for test_epochs in test_epochs_list:\n",
    "    features, response = utils.split_data(test_epochs,\n",
    "                                          n_times=NUM_TIMESTAMPS,\n",
    "                                          n_samples=EPOCH_SIZE)\n",
    "    test_features = np.concatenate([test_features, features]) if test_features.size else features\n",
    "    test_response = np.concatenate([test_response, response]) if test_response.size else response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SWLDA(penter=0.1, premove=0.15)\n",
    "clf.fit(train_features, train_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023992501128536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = clf.test(test_features, test_response)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
