{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a CNN classifier for P300 speller\n",
    "\n",
    "<div style=\"text-align:justify; width: 97%\">\n",
    "Main reference: *CNN With Large Data Achieves True Zero-Training in Online P300 Brain-Computer Interface* by J. Lee et al. (2020)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "## Python standard libraries\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "\n",
    "## Packages for computation and modelling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "# from torcheeg.models import EEGNet\n",
    "import mne\n",
    "import pickle\n",
    "\n",
    "## Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Self-defined packages\n",
    "from swlda import SWLDA\n",
    "import eegnet_utils\n",
    "import swlda_utils\n",
    "\n",
    "# Magic command to reload packages whenever we run any later cells\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD = [[\"A\",    \"B\",  \"C\",   \"D\",    \"E\",    \"F\",     \"G\",    \"H\"    ],\n",
    "         [\"I\",    \"J\",  \"K\",   \"L\",    \"M\",    \"N\",     \"O\",    \"P\"    ],\n",
    "         [\"Q\",    \"R\",  \"S\",   \"T\",    \"U\",    \"V\",     \"W\",    \"X\"    ],\n",
    "         [\"Y\",    \"Z\",  \"Sp\",  \"1\",    \"2\",    \"3\",     \"4\",    \"5\"    ],\n",
    "         [\"6\",    \"7\",  \"8\",   \"9\",    \"0\",    \"Prd\",   \"Ret\",  \"Bs\"   ],\n",
    "         [\"?\",    \",\",  \";\",   \"\\\\\",   \"/\",    \"+\",     \"-\",    \"Alt\"  ],\n",
    "         [\"Ctrl\", \"=\",  \"Del\", \"Home\", \"UpAw\", \"End\",   \"PgUp\", \"Shft\" ],\n",
    "         [\"Save\", \"'\",  \"F2\",  \"LfAw\", \"DnAw\", \"RtAw\",  \"PgDn\", \"Pause\"],\n",
    "         [\"Caps\", \"F5\", \"Tab\", \"EC\",   \"Esc\",  \"email\", \"!\",    \"Sleep\"]]\n",
    "BOARD  = np.array(BOARD)\n",
    "N_ROWS = BOARD.shape[0]  # number of rows\n",
    "N_COLS = BOARD.shape[1]  # number of columns\n",
    "M = N_ROWS * N_COLS      # the number of chars on the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm        = 'RC' # display paradigm ('RC', 'CB', or 'RD')\n",
    "NUM_TIMESTAMPS  = 195  # number of timestamps in each window to record signals\n",
    "NUM_CHANNELS    = 32   # number of eletrode channels\n",
    "EPOCH_SIZE      = 195  # size of epoch, we don't aggregrate this time\n",
    "NUM_TRAIN_WORDS = 5    # number of training words for one participant\n",
    "NUM_TEST_WORDS  = 5    # number of testing words for one participant\n",
    "obj_indices     = ['01', '02', '03', '04', '05', '06', '07',\n",
    "                   '09', '14', '15', '16', '17', '19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_list, train_Y_list, test_X_list, test_Y_list = [], [], [], []\n",
    "for obj in obj_indices:\n",
    "    directory = os.path.abspath('../../..') + '/BCI_data/EDFData-StudyA'\n",
    "    obj_directory = directory + f'/A{obj}/SE001'\n",
    "\n",
    "    train_features,train_response = eegnet_utils.load_data(dir=obj_directory,\n",
    "                                              obj=obj,\n",
    "                                              num_timestamps=NUM_TIMESTAMPS,\n",
    "                                              epoch_size=EPOCH_SIZE,\n",
    "                                              num_channels=NUM_CHANNELS,\n",
    "                                              type=paradigm,\n",
    "                                              mode='train',\n",
    "                                              num_words=NUM_TRAIN_WORDS)\n",
    "    train_X_list.append(train_features)\n",
    "    train_Y_list.append(train_response.reshape((-1, 1)))\n",
    "\n",
    "    test_features,test_response   = eegnet_utils.load_data(dir=obj_directory,\n",
    "                                              obj=obj,\n",
    "                                              num_timestamps=NUM_TIMESTAMPS,\n",
    "                                              epoch_size=EPOCH_SIZE,\n",
    "                                              num_channels=NUM_CHANNELS,\n",
    "                                              type=paradigm,\n",
    "                                              mode='test',\n",
    "                                              num_words=NUM_TEST_WORDS)\n",
    "    test_X_list.append(test_features)\n",
    "    test_Y_list.append(test_response.reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.from_numpy(np.vstack(train_X_list))\n",
    "train_Y = torch.from_numpy(np.vstack(train_Y_list))\n",
    "test_X  = torch.from_numpy(np.vstack(test_X_list))\n",
    "test_Y  = torch.from_numpy(np.vstack(test_Y_list))\n",
    "\n",
    "# Resize the features and responses to fit the EEGNet model\n",
    "train_X = torch.from_numpy(np.expand_dims(train_X, axis=1)) # [55692, 1, 32, 206]\n",
    "test_X  = torch.from_numpy(np.expand_dims(test_X,  axis=1)) # [55692, 1, 32, 206]\n",
    "\n",
    "train_Y = np.squeeze(train_Y) # [55692]\n",
    "test_Y  = np.squeeze(test_Y) # [55692]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55692, 1, 32, 206]) torch.Size([55692])\n",
      "torch.Size([55692, 1, 32, 206]) torch.Size([55692])\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_Y.shape)\n",
    "print(test_X.shape,  test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "EPOCHS = 1\n",
    "\n",
    "trainset, testset = TensorDataset(train_X, train_Y), TensorDataset(test_X, test_Y)\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader  = DataLoader(dataset=testset,  batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the EEGNet classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet = eegnet_utils.EEGNet().to(device)\n",
    "model = eegnet_utils.Model(eegnet, lr=LR)\n",
    "history = model.fit(trainloader=trainloader, validloader=testloader,\n",
    "                    epochs=EPOCHS, monitor=[\"acc\", \"val_acc\"])\n",
    "eegnet_utils.plot_acc_and_loss(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': array([0.20812429]),\n",
       " 'acc': array([0.86949652]),\n",
       " 'val_loss': array([0.35603786]),\n",
       " 'val_acc': array([0.86976586])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_indices     = ['01', '02', '03', '04', '05', '06', '07',\n",
    "                   '09', '14', '15', '16', '17', '19']\n",
    "eegnet = eegnet_utils.EEGNet().to(device)\n",
    "model_path = './model/best_eegnet_model.pt'\n",
    "model = eegnet_utils.Model(eegnet)\n",
    "model.load(filepath=model_path)\n",
    "\n",
    "eegnet_clf_test_accs = []\n",
    "for obj in obj_indices:\n",
    "    directory = os.path.abspath('../..') + '/BCI_data/EDFData-StudyA'\n",
    "    obj_directory = directory + f'/A{obj}/SE001'\n",
    "\n",
    "    test_features,test_response   = eegnet_utils.load_data(dir=obj_directory,\n",
    "                                              obj=obj,\n",
    "                                              num_timestamps=NUM_TIMESTAMPS,\n",
    "                                              epoch_size=EPOCH_SIZE,\n",
    "                                              num_channels=NUM_CHANNELS,\n",
    "                                              type=paradigm,\n",
    "                                              mode='test',\n",
    "                                              num_words=NUM_TEST_WORDS)\n",
    "    test_X  = torch.from_numpy(test_features)\n",
    "    test_Y  = torch.from_numpy(test_response)\n",
    "    test_X  = torch.from_numpy(np.expand_dims(test_X,  axis=1))\n",
    "    test_Y  = np.squeeze(test_Y)\n",
    "\n",
    "    testset = TensorDataset(test_X, test_Y)\n",
    "    BATCH_SIZE = 1\n",
    "    dataloader = DataLoader(dataset=testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loss, test_acc = model.evaluate(dataloader)\n",
    "    eegnet_clf_test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "EEGNet                                   [4284, 2]                 --\n",
       "├─Sequential: 1-1                        [4284, 64, 32, 207]       --\n",
       "│    └─Conv2d: 2-1                       [4284, 64, 32, 207]       4,096\n",
       "│    └─BatchNorm2d: 2-2                  [4284, 64, 32, 207]       128\n",
       "├─Sequential: 1-2                        [4284, 256, 1, 51]        --\n",
       "│    └─Conv2d: 2-3                       [4284, 256, 1, 207]       8,192\n",
       "│    └─BatchNorm2d: 2-4                  [4284, 256, 1, 207]       512\n",
       "│    └─ELU: 2-5                          [4284, 256, 1, 207]       --\n",
       "│    └─AvgPool2d: 2-6                    [4284, 256, 1, 51]        --\n",
       "│    └─Dropout: 2-7                      [4284, 256, 1, 51]        --\n",
       "├─Sequential: 1-3                        [4284, 256, 1, 6]         --\n",
       "│    └─Conv2d: 2-8                       [4284, 256, 1, 52]        4,096\n",
       "│    └─Conv2d: 2-9                       [4284, 256, 1, 52]        65,536\n",
       "│    └─BatchNorm2d: 2-10                 [4284, 256, 1, 52]        512\n",
       "│    └─ELU: 2-11                         [4284, 256, 1, 52]        --\n",
       "│    └─AvgPool2d: 2-12                   [4284, 256, 1, 6]         --\n",
       "│    └─Dropout: 2-13                     [4284, 256, 1, 6]         --\n",
       "├─Linear: 1-4                            [4284, 2]                 3,074\n",
       "==========================================================================================\n",
       "Total params: 86,146\n",
       "Trainable params: 86,146\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 139.03\n",
       "==========================================================================================\n",
       "Input size (MB): 112.96\n",
       "Forward/backward pass size (MB): 34059.31\n",
       "Params size (MB): 0.34\n",
       "Estimated Total Size (MB): 34172.61\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.model, input_size=(4284, 1, 32, 206))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegnet_clf_test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8823529411764706]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegnet_clf_test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the SWLDA classifier (benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_indices = ['01', '02', '03', '04', '05', '06', '07',\n",
    "               '09', '14', '15', '16', '17', '19']\n",
    "CORE_CHANNELS = ('EEG_Fz', 'EEG_Cz',  'EEG_P3',  'EEG_Pz',\n",
    "                 'EEG_P4', 'EEG_PO7', 'EEG_PO8', 'EEG_Oz')\n",
    "NUM_CORE_CHANNELS = 8\n",
    "\n",
    "swlda_clf_test_accs = []\n",
    "\n",
    "for obj in obj_indices:\n",
    "    directory = os.path.abspath('../..') + '/BCI_data/EDFData-StudyA'\n",
    "    obj_directory = directory + f'/A{obj}/SE001'\n",
    "\n",
    "    train_features,train_response = swlda_utils.load_data(dir=obj_directory,\n",
    "                                              obj=obj,\n",
    "                                              num_timestamps=NUM_TIMESTAMPS,\n",
    "                                              epoch_size=EPOCH_SIZE,\n",
    "                                              num_channels=NUM_CORE_CHANNELS,\n",
    "                                              type=paradigm,\n",
    "                                              mode='train',\n",
    "                                              num_words=NUM_TRAIN_WORDS)\n",
    "\n",
    "    test_features,test_response   = swlda_utils.load_data(dir=obj_directory,\n",
    "                                              obj=obj,\n",
    "                                              num_timestamps=NUM_TIMESTAMPS,\n",
    "                                              epoch_size=EPOCH_SIZE,\n",
    "                                              num_channels=NUM_CORE_CHANNELS,\n",
    "                                              type=paradigm,\n",
    "                                              mode='test',\n",
    "                                              num_words=NUM_TEST_WORDS)\n",
    "\n",
    "    try:\n",
    "        f = open(f'./model/A{obj}-swlda-model.pkl', 'rb')\n",
    "        clf = pickle.load(f)\n",
    "    except:\n",
    "        clf = SWLDA(penter=0.1, premove=0.15)\n",
    "        clf.fit(train_features, train_response)\n",
    "        # save the classifier as a standalone model file\n",
    "        with open(f'./model/A{obj}-swlda-model.pkl','wb') as f:\n",
    "            pickle.dump(clf,f)\n",
    "\n",
    "    pred = clf.test(test_features) > 0.5\n",
    "    test_acc = sum(pred == test_response) / len(pred)\n",
    "    swlda_clf_test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8828197945845004,\n",
       " 0.8895891690009337,\n",
       " 0.8839869281045751,\n",
       " 0.8930905695611578,\n",
       " 0.8828197945845004,\n",
       " 0.892623716153128,\n",
       " 0.888422035480859,\n",
       " 0.8830532212885154,\n",
       " 0.8825863678804855,\n",
       " 0.8821195144724556,\n",
       " 0.8818860877684407,\n",
       " 0.8823529411764706,\n",
       " 0.8823529411764706]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swlda_clf_test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8852079293255765"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(swlda_clf_test_accs) / len(swlda_clf_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
